{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(\"../data/aclImdb/train/\")\n",
    "#load_files返回一个Bunch对象，其中包含训练文本和训练标签\n",
    "text_train,y_train = reviews_train.data,reviews_train.target\n",
    "print(\"type of text_train:{}\".format(type(text_train)))\n",
    "print(\"length of text_train:{}\".format(len(text_train)))\n",
    "print(\"text_train[1]:\\n{}\".format(text_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去掉无标签的50000个数据\n",
    "text_train_labeled = pd.DataFrame(text_train)[y_train != 2]\n",
    "y_train_labeled = pd.DataFrame(y_train)[y_train !=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"type of text_train:{}\".format(type(text_train_labeled)))\n",
    "print(\"length of text_train:{}\".format(len(text_train_labeled)))\n",
    "print(\"text_train[1]:\\n{}\".format(text_train_labeled.iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train_labeled = [doc[0].replace(b\"<br />\",b\" \") for doc in np.array(text_train_labeled)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_labeled = y_train_labeled.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(y_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"../data/aclImdb/test/\")\n",
    "#load_files返回一个Bunch对象，其中包含训练文本和训练标签\n",
    "text_test,y_test = reviews_test.data,reviews_test.target\n",
    "print(len(text_test))\n",
    "print(np.bincount(y_test))\n",
    "text_test = [doc.replace(b\"<br />\",b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_word = [\"The fool doth think he is wise,\",\n",
    "             \"but the wise man knows himself to be a fool\"]\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "vec.fit(bards_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vec.vocabulary_))\n",
    "print(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vec.transform(bards_word)\n",
    "print(repr(bag_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train_labeled)\n",
    "X_train = vect.transform(text_train_labeled)\n",
    "print(repr(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = vect.get_feature_names()\n",
    "print(\"Number of features:{}\".format(len(features_names)))\n",
    "print(\"First 20 features:\\n{}\".format(features_names[:20]))\n",
    "print(\"Features 20010 to 20030:\\n{}\".format(features_names[20010:20030]))\n",
    "print(\"Every 2000th feature:\\n{}\".format(features_names[::2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(LogisticRegression(),X_train,y_train_labeled,cv=5)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.001,0.01,0.1,1,10]}\n",
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5)\n",
    "grid.fit(X_train,y_train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=5).fit(text_train_labeled)\n",
    "X_train = vect.transform(text_train_labeled)\n",
    "print(repr(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_names = vect.get_feature_names()\n",
    "print(features_names[:50])\n",
    "print(features_names[20010:20030])\n",
    "print(features_names[::700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5)\n",
    "grid.fit(X_train,y_train_labeled)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ENGLISH_STOP_WORDS))\n",
    "print(list(ENGLISH_STOP_WORDS)[::10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定stop_words=\"english\"将使用内置列表\n",
    "#也可以扩展这个列表并传入自定义列表\n",
    "vect = CountVectorizer(min_df=5,stop_words=\"english\").fit(text_train_labeled)\n",
    "X_train = vect.transform(text_train_labeled)\n",
    "print(repr(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(LogisticRegression(),param_grid,cv=5)\n",
    "grid.fit(X_train,y_train_labeled)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfTransformer(),LogisticRegression())\n",
    "param_grid = {'logisticregression__C':[0.001,0.01,0.1,1,10]}\n",
    "grid = GridSearchCV(pipe,param_grid,cv=5)\n",
    "grid.fit(X_train,y_train_labeled)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(),LogisticRegression())\n",
    "param_grid = {'logisticregression__C':[0.001,0.01,0.1,1,10]}\n",
    "grid = GridSearchCV(pipe,param_grid,cv=5)\n",
    "grid.fit(text_train_labeled,y_train_labeled)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = grid.best_estimator_.named_steps[\"tfidfvectorizer\"]\n",
    "X_train = vectorizer.transform(text_train_labeled)\n",
    "#找到数据集中每个特征的最大值\n",
    "max_value = X_train.max(axis=0).toarray().ravel()\n",
    "sorted_by_tfidf = max_value.argsort()\n",
    "#获取特征名称\n",
    "features_names = np.array(vectorizer.get_feature_names())\n",
    "print(features_names[sorted_by_tfidf[:20]])\n",
    "print(features_names[sorted_by_tfidf[-20:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_idf = np.argsort(vectorizer.idf_)\n",
    "print(features_names[sorted_by_idf[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
